%We present ROBOSHERLOCK, an open source
software framework for implementing perception systems for
robots performing human-scale everyday manipulation tasks.
In ROBOSHERLOCK, perception and interpretation of realistic
scenes is formulated as an unstructured information manage-
ent (UIM) problem. The application of the UIM principle
supports the implementation of perception systems that can
answer task-relevant queries about objects in a scene, boost
object recognition performance by combining the strengths
of multiple perception algorithms, support knowledge-enabled
reasoning about objects and enable automatic and knowledge-
driven generation of processing pipelines.
ROBOSHERLOCK uses annotations in form of logical
atoms in order to be able to ask structured queries and
perform logical reasoning about annotations added by the
AEs. The main reasoning engine used in ROBOSHERLOCK is
based on SWI-Prolog, a general purpose logic programming
language providing bindings for the most common proce-
nural languages like C++, Java. AEs can be equipped with
Prolog programs, which consist of facts and rules. Relevant
annotations are automatically asserted as facts into the Prolog
knowledge base.


@inproceedings{beetz2015robosherlock,
  title={RoboSherlock: Unstructured information processing for robot perception},
  author={Beetz, Michael and Balint-Benczedi, Ferenc and Blodow, Nico and Nyga, Daniel and Wiedemeyer, Thiemo and Marton, Zoltan-Csaba},
  booktitle={Robotics and Automation (ICRA), 2015 IEEE International Conference on},
  pages={1549--1556},
  year={2015},
  organization={IEEE}
}

Abstract. Mental models play an important and sometimes critical role
in human-human interactions, in particular, in the context of human
team tasks where humans need to interact with each other to achieve
common goals. In this paper, we will describe some of the challenges
involved in developing general computational mechanisms for mental
models and their applications in the context human-robot interactions
in mixed initiative tasks.
@incollection{scheutz2013computational,
  title={Computational mechanisms for mental models in human-robot interaction},
  author={Scheutz, Matthias},
  booktitle={Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments},
  pages={304--312},
  year={2013},
  publisher={Springer}
}


Abstract— In human-robot interaction, a robot must be
prepared to handle possible ambiguities generated by a human
partner. In this work we propose a set of strategies that allow a
robot to identify the referent when the human partner refers to
an object giving incomplete information, i.e. an ambiguous de-
scription. Moreover, we propose the use of an ontology to store
and reason on the robot’s knowledge to ease clarification, and
therefore, improve interaction. We validate our work through
both simulation and two real robotic platforms performing two
tasks: a daily-life situation and a game.

@inproceedings{Ros2010b,
  author = "Ros, R. and Lemaignan, S. and Sisbot, E.A. and Alami, R. and Steinwender, J. and Hamann, K. and Warneken, F.",
  booktitle = "{19th IEEE International Symposium in Robot and Human Interactive Communication}",
  title = "{Which One? Grounding the Referent Based on Efficient Human-Robot Interaction}",
  year = "2010"
}


Abstract—We propose that an important aspect of human–robot
interaction is perspective-taking. We show how perspective-taking
occurs in a naturalistic environment (astronauts working on a col-
laborative project) and present a cognitive architecture for per-
forming perspective-taking called Polyscheme. Finally, we show a
fully integrated system that instantiates our theoretical framework
within a working robot system. Our system successfully solves a
series of perspective-taking problems and uses the same frames
of references that astronauts do to facilitate collaborative problem
solving with a person.

@article{Trafton2005,
  Author = {Trafton, J. and Cassimatis, N. and Bugajska, M. and Brock, D. and Mintz, F. and Schultz, A.},
  Journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  Title = {Enabling Effective Human-robot Interaction Using Perspective-taking in Robots},
  volume    = {35},
  number    = {4},
  year      = {2005},
  pages     = {460-470}
}

This paper addresses an important issue in learning from demonstrations that are provided by “na ̈ıve” human teachers—people who do not have expertise in the machine learning algorithms used by the robot. We therefore entertain the possibility that, whereas the average human user may provide sensible demonstrations from a human’s perspective, these same demonstrations may be insufficient, incomplete, ambiguous, or otherwise “flawed” from the perspective of the training set needed by the learning algorithm to generalize properly. To address this issue, we present a system where the robot is modeled as a socially engaged and socially cognitive learner. We illustrate the merits of this approach through an example where the robot is able to correctly learn from “flawed” demonstrations by taking the visual perspective of the human instructor to

clarify potential ambiguities.


@article{breazeal2006,
  Author = {Breazeal, C. and Berlin, M. and Brooks, A. and Gray, J. and Thomaz, A.},
  Journal = {Robotics and Autonomous Systems},
  Title = {Using Perspective Taking to Learn from Ambiguous Demonstrations},
  Year = {2006}
}



Divergent Belief Task:
@article{BreazealGB09,
  author    = {Cynthia Breazeal and
               Jesse Gray and
               Matt Berlin},
  title     = {An Embodied Cognition Approach to Mindreading Skills for
               Socially Intelligent Robots},
  journal   = {I. J. Robotic Res.},
  year      = {2009}
}
Future applications for personal robots motivate research into developing
robots that are intelligent in their interactions with people. Toward
this goal, in this paper we present an integrated socio-cognitive
architecture to endow an anthropomorphic robot with the ability to
infer mental states such as beliefs, intents, and desires from the observable
behavior of its human partner. The design of our architecture
is informed by recent findings from neuroscience and embodies cognition
that reveals how living systems leverage their physical and cognitive
embodiment through simulation-theoretic mechanisms to infer
the mental states of others. We assess the robot’s mindreading skills
on a suite of benchmark tasks where the robot interacts with a human
partner in a cooperative scenario and a learning scenario. In addition,
we have conducted human subjects experiments using the same
task scenarios to assess human performance on these tasks and to
compare the robot’s performance with that of people. In the process,
our human subject studies also reveal some interesting insights into
human behavior




Intention Recognition:
@article{koppula2016anticipating,
  title={Anticipating human activities using object affordances for reactive robotic response},
  author={Koppula, Hema S and Saxena, Ashutosh},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={38},
  number={1},
  pages={14--29},
  year={2016},
  publisher={IEEE}
}

@article{demiris2007prediction,
  author = "Demiris, Yiannis",
  journal = "Cognitive processing",
  number = "3",
  pages = "151--158",
  publisher = "Springer",
  title = "{Prediction of intent in robotics and multi-agent systems}",
  volume = "8",
  year = "2007"
}




}

@INPROCEEDINGS{Milliez2014,
author={Milliez, G. and Warnier, M. and Clodic, A. and Alami, R.},
booktitle={Robot and Human Interactive Communication, 2014 RO-MAN: The 23rd IEEE International Symposium on},
title={A framework for endowing an interactive robot with reasoning capabilities about perspective-taking and belief management},
year={2014},
month={Aug},
pages={1103-1109},
doi={10.1109/ROMAN.2014.6926399},
}





@inproceedings{Clair2010,
  author = "Aaron B. St. Clair, Ross Mead and Maja J. Matari{\'c}",
  title = "Monitoring and Guiding User Attention and Intention in Human-Robot Interaction",
  booktitle = "2010 IEEE International Conference on Robotics and Automation Workshop on Interactive Communication for Autonomous Intelligent Robots",
  address = "Anchorage, Alaska",
  month = "May",
  year = "2010",
  url = "http://robotics.usc.edu/publications/668/"
}





@article{Althaus2004,
  author = "Althaus, P. and Ishiguro, H. and Kanda, T. and Miyashita, T. and Christensen, H.I.",
  journal = "IEEE Int. Conf. on Robotics \& Automation, New Orleans, USA",
  title = "{Navigation for Human-Robot Interaction Tasks}",
  year = "2004"
}

@techreport{Berg2004,
  author = "Berg, J. van den and Overmars, M.",
  institution = "Utrecht University, NL",
  title = "{Roadmap-based Motion Planning in Dynamic Environments}",
  year = "2004"
}




@article{Johnson2005,
  author = "Johnson, M. and Demiris, Y.",
  journal = "Advanced Robotic Systems",
  number = "4",
  pages = "301--308",
  title = "{Perceptual Perspective Taking and Action Recognition}",
  volume = "2",
  year = "2005"
}




@article{Scassellati2002,
  author = "Scassellati, B.",
  journal = "Autonomous Robots",
  number = "1",
  pages = "13--24",
  publisher = "Springer",
  title = "{Theory of mind for a humanoid robot}",
  volume = "12",
  year = "2002"
}

@article{Sidner2005,
  author = "Sidner, C. L. and Lee, C. and Kidd, C. and Lesh, N. and Rich, C.",
  journal = "Artificial Intelligence",
  number = "1-2",
  pages = "140--164",
  title = "{Explorations in Engagement for Humans and Robots}",
  volume = "166",
  year = "2005"
}





@inproceedings{ros2010one,
  author = "Ros, Raquel and Lemaignan, S{\'e}verin and Sisbot, Emrah Akin and Alami, Rachid and Steinwender, Jasmin and Hamann, Katharina and Warneken, Felix",
  booktitle = "{RO-MAN, 2010 IEEE}",
  organization = "IEEE",
  pages = "570--575",
  title = "{Which one? grounding the referent based on efficient human-robot interaction}",
  year = "2010"
}



@inproceedings{gray2005action,
  author = "Gray, Jesse and Breazeal, Cynthia and Berlin, Matt and Brooks, Andrew and Lieberman, Jeff",
  booktitle = "{Robot and Human Interactive Communication, 2005. ROMAN 2005. IEEE International Workshop on}",
  organization = "IEEE",
  pages = "202--209",
  title = "{Action parsing and goal inference using self as simulator}",
  year = "2005"
}

@article{bicho2011neuro,
  author = "Bicho, Estela and Erlhagen, Wolfram and Louro, Luis and {Costa e Silva}, Eliana",
  journal = "Human movement science",
  number = "5",
  pages = "846--868",
  publisher = "Elsevier",
  title = "{Neuro-cognitive mechanisms of decision making in joint action: A human--robot interaction study}",
  volume = "30",
  year = "2011"
}

@inproceedings{breazeal2004teaching,
  author = "Breazeal, Cynthia and Hoffman, Guy and Lockerd, Andrea",
  booktitle = "{Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems-Volume 3}",
  organization = "IEEE Computer Society",
  pages = "1030--1037",
  title = "{Teaching and working with robots as a collaboration}",
  year = "2004"
}


@article{trafton2013act,
  author = "Trafton, Greg and Hiatt, Laura and Harrison, Anthony and Tamborello, Frank and Khemlani, Sangeet and Schultz, Alan",
  journal = "Journal of Human-Robot Interaction",
  number = "1",
  pages = "30--55",
  title = "{ACT-R/E: An Embodied Cognitive Architecture for Human-Robot Interaction}",
  volume = "2",
  year = "2013"
}

@inproceedings{clodic2007management,
  author = "Clodic, Aur{\'e}lie and Ransan, Maxime and Alami, Rachid and Montreuil, Vincent",
  booktitle = "{Systems, Man and Cybernetics, 2007. ISIC. IEEE International Conference on}",
  organization = "IEEE",
  pages = "1551--1556",
  title = "{A management of mutual belief for human-robot interaction}",
  year = "2007"
}




@article{johnson2005perceptual,
  author = "Johnson, Matthew and Demiris, Yiannis",
  journal = "International Journal of Advanced Robotic Systems",
  number = "4",
  title = "{Perceptual Perspective Taking and Action Recognition.}",
  volume = "2",
  year = "2005"
}



@inproceedings{warnier2012when,
  author = {Warnier, M. and Guitton, J. and Lemaignan, S. and Alami, R.},
  title = {When the Robot Puts Itself in Your Shoes. Managing and Exploiting Human and Robot Beliefs},
  booktitle = {Proceedings of the 21th IEEE International Symposium in Robot and Human Interactive Communication},
  year = {2012},
}



@inproceedings {Urias2008,
  author = {Luis Felipe Marin-Urias, E. Akin Sisbot, Rachid Alami},
  title = {Geometric Tools for Perspective Taking for Human-Robot Interaction},
  journal = {Seventh Mexican International Conference on Artificial Intelligence},
  year = {2008}
}

@INPROCEEDINGS{Warnier2012a,
  author = {Mathieu Warnier and Julien Guitton and Séverin Lemaignan and Rachid
        Alami},
  title = {When the robot puts itself in your shoes. {E}xplicit geometric management
        of position beliefs.},
  booktitle = {ISRHIC},
  year = {2012},
}



@article{BreazealGB09,
  author    = {Cynthia Breazeal and
               Jesse Gray and
               Matt Berlin},
  title     = {An Embodied Cognition Approach to Mindreading Skills for
               Socially Intelligent Robots},
  journal   = {I. J. Robotic Res.},
  year      = {2009}
}

@article{breazeal2006,
  Author = {Breazeal, C. and Berlin, M. and Brooks, A. and Gray, J. and Thomaz, A.},
  Journal = {Robotics and Autonomous Systems},
  Title = {Using Perspective Taking to Learn from Ambiguous Demonstrations},
  Year = {2006}
}

@article{Johnson2005,
  Author = {Johnson, M. and Demiris, Y.},
  Journal = {Advanced Robotic Systems},
  Title = {Perceptual Perspective Taking and Action Recognition},
  Year = {2005}
}

@INPROCEEDINGS{Saxena2013,
  author = {Hema S Koppula, Ashutosh Saxena},
  title = {Anticipating Human Activities using Object Affordances for Reactive Robotic Response},
  booktitle = {Robotics: Science and Systems (RSS)},
  year 