% Chapter Template



\chapter{Introduction} % Main chapter title

\label{chapter:introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 1. \emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

In the current days robots are starting to be introduced in our lives more and more, and we can expect that, in the next decade, they will complete the transition from mechanic tools, used mostly in industries, to true partners and companions. There is an increasing interest in studying how robots should behave in environments inhabited by humans, and, in some works, robots have been deployed in crowded and dynamic environments, like airports and museums.

Human-Robot cooperation poses a multitude of problems. Imagine a mobile robot working in a warehouse, carrying and sorting crates in different locations. Already, we are presented with quite a complex problem, where the robot needs to have a good representation of the world (i.e. position of the crates, obstacles, layout of the warehouse), to create plans to reach the goal (which crates to move, where to bring them, which paths to follow), and to have sufficient motion and manipulation skills to achieve them. If humans are present in the environment, they should be represented and considered by the robot in its plans and actions.  Modeling humans as simple moving obstacles might not be enough if we consider issues of trust, legibility, and acceptability. The robot should respect a number of social rules in the presence of humans, like maintaining a socially acceptable distance, whenever possible, from them, and approaching them from a visible position.

The problem becomes even more complex when robots and humans need to cooperate to solve a goal, for example by sorting together the crates, or even by sharing the load of heavy objects. To understand  how to approach this problem we can observe how humans cooperate with themselves. Research in psychology and philosophy \citep{pacherie2012phenomenology} characterizes the execution of cooperative actions as `joint actions'. \cite{sebanz2006joint} have proposed that the execution of a joint action depends on three different abilities: sharing representations, predicting actions, and integrating predicted effects of own and other's actions. These abilities can be achieved by the combination of different mechanisms:
\begin{itemize}
\item Joint Attention. The ability to direct a partner's attention, in order to create a shared representation of objects and events. Humans use a large number of social cues, like gaze direction or pointing gestures, to indicate what is currently under observation. This mechanism helps filling important gaps in the knowledge of a partner, and points to the importance of understanding what others know and perceive.
\item Action Observation. Observing other partners' actions is crucial in understanding what are their goals. Studies have shown that observing a person performing an action produces a motor resonance, which increases with the observer's level of expertise in the action. Understanding what others are doing allows to predict the outcomes of their activities, and even their next movements.
\item Task Sharing. Humans are able to predict, in some circumstances, what others will do  even without direct observation. A notable example is a well trained sport team, which is able to act like a single entity, coordinating seamlessly. This ability suggests that humans possess a shared representation of tasks, which include actions that should be performed by each partner of the team.
\item Action Coordination. Predicting actions is not enough. Humans also need to choose a complementary action and adjust its parameters to partners, like the exact moment and place where it should be performed. 
\end{itemize}

It seems that robots need to have an equivalent of these mechanism, in order to cooperate in a natural and acceptable way with humans. Is this enough to create robot partners? Unfortunately, we just scratched the surface of the problem. While these areas are already very complex, and not completely understood, humans possess other skills that should be translated to robots. For example, when a robot's behavior shows a degree of intelligence, humans usually try to have a conversation with it, which can lead to frustration or disbelief in the actual capacities of the robot. Issues such as dialogue, representation, and refinement of knowledge are very complex and will not be a direct focus of this work.

The goal of this work is, instead, to provide a framework to allow a robot to work in social environments and execute joint actions with humans in a natural way. We have built our system using psychology as an inspiration, without trying to replicate accurately human mechanisms, an area of work studied in cognitive systems. 

\section*{Contributions}

The main contributions of this work are the following:
\begin{itemize}
\item Building a supervision system for Human-Robot Interaction (HRI). The aim of this system is being able to execute cooperative human-robot actions in a natural and efficient way. It has been built by integrating new components, developed in this work, with existing ones.
\item Developing a novel algorithm to infer human intentions and actions. This algorithm, based on Markov Decision Processes (MDP), and Bayesian Networks (BN), allows the robot to better understand humans by reasoning not only on their actions, but also on their knowledge and awareness of the environment. The algorithm is efficient and scalable, and has been tested in a user study to prove that it is able to approach the capacity of humans to infer intentions.
\item Developing a framework to execute joint actions between the robot and a human. This framework is based on Mixed Observability Markov Decision Processes (MOMDP) and has been applied to two different examples: the handover and  the robot guide.
\item Developing a multi-agent probabilistic planning algorithm, based on MDPs. This planner is able, starting from a list of single-agent MDP models, to build a multi-agent model, taking into account issues such as cooperation and conflicts in the agents' actions. The planner was developed to work on tightly coupled problems, where agents interactions are frequent. The complexity associated to MDPs is partially mitigated by introducing features such as parameters, abstract states, and hierarchical models.
\item Evaluating the different components in user studies. We have performed two user studies to evaluate the capacity of the system to infer human intentions, and how its adaptive plan explanation and management skills are perceived by humans. In addition, parts of the system, joined with components of other partners in an European project, where evaluated with real users in a robot guide scenario, ran at the airport of Schiphol in Amsterdam.
\end{itemize}

\section{Organization of the Thesis}
During the development of our work we identified three different aspects of our robot: the observer, the coworker, and the teacher. This thesis is organized in different parts, reflecting these aspects.

Part~\ref{part:robot_observer} introduces the problem of the robot observer, where a robot is constantly monitoring the activities of humans in the environment, trying to infer their goals and to help them achieve it.  Chapter~\ref{chapter:belief_management} shows how the robot is able to use geometrical reasoning to understand what humans know about the current environment. Chapter~\ref{chapter:intention} introduces our intention and action recognition algorithm, showing how the robot can use it to infer what actions humans execute, and how they connect to his possible intentions. Chapter~\ref{chapter:observer_results} shows our experiments in this problem, where we compared our algorithm with humans prediction in a user study.

Part~\ref{part:robot_coworker} introduces the robot coworker problem, where a robot has to complete a cooperative scenario with a human helper. Chapter~\ref{chapter:plan_management} analyzes how our system is able to produce shared plans, which include both the robot and humans, and how it is able to manage them, synchronizing with humans. Chapter~\ref{chapter:task_execution} explains how the robot is able to execute tasks and, in particular, introduces the Collaborative Planners, a framework that we use to represent and execute joint actions. Chapter~\ref{chapter:coworker_experiments} introduces a human-robot cooperative scenario, showing how our system is able to handle several possible situations. Chapter ~\ref{chapter:mamdp} introduces the Multi-Agent Markov Decision Process, a probabilistic model that we have recently developed to extend the capacity of the robot coworker.

Part~\ref{part:robot_teacher} discusses about how a robot can teach a task to users, adapting its explanations to their expertise in the domain. Chapter~\ref{chapter:knowledge} explains how we are able to model and update a human's expertise in a task and how the robot can adapt its explanations to this model. We also evaluate different strategies in collaborative planning, favoring teaching or efficiency. Chapter~\ref{chapter:teacher_results} shows a user study that evaluates our algorithm to teach a cooperative task.

Part~\ref{part:case_study} presents a complex case study, where we cooperated in the development of a human-aware robot guide, which was then deployed in the Schiphol Airport of Amsterdam. Chapter~\ref{chapter:spencer} shows how we designed this system, adapting the capacities explained in the previous parts. Chapter~\ref{chapter:spencer_results} shows our experiments, performed both in a laboratory environment and in the airport, with real passengers.

Finally, Part~\ref{part:conclusions} concludes this thesis. Chapter~\ref{chapter-conclusions} reviews our achievements and discusses possible future works. We also present in this part appendix~\ref{appendix-methods}, where we introduce in a formal way the models used in the our work.

\section{Published Works}
\begin{itemize}
\item Milliez, Grégoire, et al. ``Simulating human-robot interactions for dialogue strategy learning." Simulation, Modeling, and Programming for Autonomous Robots. Springer International Publishing, 2014. 62-73.
\item Triebel, Rudolph, et al. ``SPENCER: A socially aware service robot for passenger guidance and help in busy airports.", 2015.
\item Fiore, Michelangelo, et al. ``An Adaptive and Proactive Human-Aware Robot Guide." Social Robotics. Springer International Publishing, 2015. 194-203.
\item Fiore Michelangelo, et al. ``On planning and task achievement modalities for human-robot collaboration." Experimental Robotics. Springer International Publishing, 2016.
\item Milliez, Grégoire, et al. ``Using human knowledge awareness to adapt collaborative plan generation, explanation and monitoring." The Eleventh ACM/IEEE International Conference on Human Robot Interaction. IEEE Press, 2016.
\item Devin, Sandra et al. ``Some essential skills and their combination in an architecture for a cognitive and interactive" robot arXiv preprint arXiv:1603.00583, 2016
\item Caccavale, Riccardo, et al. ``Attentional Supervision of Human-Robot Collaborative Plans." The IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 2016.
\end{itemize}


