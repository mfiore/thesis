Cookie Scenario:

Test 0: robot mental model and no context

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 0.5 
p(node BreakTime==1) = 0.5 
p(node DrinkWater==0) = 0.5 
p(node DrinkWater==1) = 0.5 
p(node EatCookie==0) = 0.5 
p(node EatCookie==1) = 0.5 
p(node HotDay==0) = 0.5 
p(node HotDay==1) = 0.5 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node agent_move_kitchen==0) = 0.998267 
p(node agent_move_kitchen==1) = 0.0017331 
p(node agent_move_table==0) = 0.0017331 
p(node agent_move_table==1) = 0.998267 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 


Test 1: robot mental model and context

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 0.52 
p(node BreakTime==1) = 0.48 
p(node DrinkWater==0) = 0.4 
p(node DrinkWater==1) = 0.6 
p(node EatCookie==0) = 0.6 
p(node EatCookie==1) = 0.4 
p(node HotDay==0) = 0 
p(node HotDay==1) = 1 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node agent_move_kitchen==0) = 0.998267 
p(node agent_move_kitchen==1) = 0.0017331 
p(node agent_move_table==0) = 0.0017331 
p(node agent_move_table==1) = 0.998267 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 


Test 2: Divergent Belief Max

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 1 
p(node BreakTime==1) = 0 
p(node DrinkWater==0) = 0.0468936 
p(node DrinkWater==1) = 0.953106 
p(node EatCookie==0) = 1 
p(node EatCookie==1) = 0 
p(node FillCookieBox==0) = 0.953106 
p(node FillCookieBox==1) = 0.0468936 
p(node HotDay==0) = 0 
p(node HotDay==1) = 1 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node agent_move_kitchen==0) = 0.992567 
p(node agent_move_kitchen==1) = 0.00743324 
p(node agent_move_table==0) = 0.00743324 
p(node agent_move_table==1) = 0.992567 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 


Test 3: Divergent Belief Bob

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 1 
p(node BreakTime==1) = 0 
p(node DrinkWater==0) = 0.360665 
p(node DrinkWater==1) = 0.639335 
p(node EatCookie==0) = 0.75137 
p(node EatCookie==1) = 0.24863 
p(node FillCookieBox==0) = 0.887966 
p(node FillCookieBox==1) = 0.112034 
p(node HotDay==0) = 0 
p(node HotDay==1) = 1 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node agent_move_kitchen==0) = 0.996737 
p(node agent_move_kitchen==1) = 0.00326254 
p(node agent_move_table==0) = 0.00326254 
p(node agent_move_table==1) = 0.996737 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 



Keys:
Test 1 : No context and robot state

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 0.5 
p(node BreakTime==1) = 0.5 
p(node GetKeys==0) = 1 
p(node GetKeys==1) = 0 
p(node GetMug==0) = 0.5 
p(node GetMug==1) = 0.5 
p(node HotDay==0) = 0.5 
p(node HotDay==1) = 0.5 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node ReadBook==0) = 0.5 
p(node ReadBook==1) = 0.5 
p(node TimeToLeave==0) = 0.6 
p(node TimeToLeave==1) = 0.4 
p(node agent_move_kitchen==0) = 0.998267 
p(node agent_move_kitchen==1) = 0.0017331 
p(node agent_move_table==0) = 0.0017331 
p(node agent_move_table==1) = 0.998267 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 



Test 2: Context and robot state

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 1 
p(node BreakTime==1) = 0 
p(node GetKeys==0) = 1 
p(node GetKeys==1) = 0 
p(node GetMug==0) = 0.5 
p(node GetMug==1) = 0.5 
p(node HotDay==0) = 1 
p(node HotDay==1) = 0 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node ReadBook==0) = 0.5 
p(node ReadBook==1) = 0.5 
p(node TimeToLeave==0) = 0 
p(node TimeToLeave==1) = 1 
p(node agent_move_kitchen==0) = 0.998267 
p(node agent_move_kitchen==1) = 0.0017331 
p(node agent_move_table==0) = 0.0017331 
p(node agent_move_table==1) = 0.998267 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 


Test 3: Context and Mental State

p(node ActionsOr==0) = 0 
p(node ActionsOr==1) = 1 
p(node BreakTime==0) = 1 
p(node BreakTime==1) = 0 
p(node GetKeys==0) = 0.22 
p(node GetKeys==1) = 0.78 
p(node GetMug==0) = 0.78 
p(node GetMug==1) = 0.22 
p(node HotDay==0) = 1 
p(node HotDay==1) = 0 
p(node IntentionsOr==0) = 0 
p(node IntentionsOr==1) = 1 
p(node ReadBook==0) = 1 
p(node ReadBook==1) = 0 
p(node TimeToLeave==0) = 0 
p(node TimeToLeave==1) = 1 
p(node agent_move_kitchen==0) = 0.998267 
p(node agent_move_kitchen==1) = 0.0017331 
p(node agent_move_table==0) = 0.0017331 
p(node agent_move_table==1) = 0.998267 
p(node distance_agent_move_kitchen==0) = 0 
p(node distance_agent_move_kitchen==1) = 1 
p(node distance_agent_move_kitchen==2) = 0 
p(node distance_agent_move_kitchen==3) = 0 
p(node distance_agent_move_kitchen==4) = 0 
p(node distance_agent_move_table==0) = 0 
p(node distance_agent_move_table==1) = 0 
p(node distance_agent_move_table==2) = 0 
p(node distance_agent_move_table==3) = 1 
p(node distance_agent_move_table==4) = 0 
p(node toward_agent_move_kitchen==0) = 1 
p(node toward_agent_move_kitchen==1) = 0 
p(node toward_agent_move_table==0) = 0 
p(node toward_agent_move_table==1) = 1 






